# 05_sql_sqlite.qmd
---
title: "05 — SQL & SQLite (Python)"
format: html
execute:
  echo: true
---

Introduction — This page shows a small Python script that creates a local SQLite database, writes two tables from pandas DataFrames (`features` and `weekday_meta`), runs a JOIN query using SQL, and prints the result. The follow-up shell commands show how to run the script. Explanations below focus on the SQLite usage from the Python code and the example SQL query.

```{python}
from pathlib import Path
import sqlite3
import pandas as pd

Path("db").mkdir(parents=True, exist_ok=True)
con = sqlite3.connect("db/synth.db")
try:
    df = pd.read_csv("data/processed/synth_features.csv")
    if "weekday" in df.columns:
        df["weekday"] = df["weekday"].astype(int)
    df.to_sql("features", con, if_exists="replace", index=False)

    meta = pd.DataFrame({
        "weekday": [1,2,3,4,5,6,7],
        "weekday_name": ["Mon","Tue","Wed","Thu","Fri","Sat","Sun"]
    })
    meta.to_sql("weekday_meta", con, if_exists="replace", index=False)

    q = """
    SELECT f.date, f.price, f.volume, f.log_return, f.sma_5, m.weekday_name
    FROM features f JOIN weekday_meta m USING(weekday)
    ORDER BY date LIMIT 10;
    """
    print(pd.read_sql(q, con))
finally:
    con.close()
```

The Python code and SQLite explanations:

- `sqlite3.connect("db/synth.db")`  
  Opens (or creates) a local SQLite database file at `db/synth.db`. The returned connection `con` is used for all subsequent SQL operations.

- `df = pd.read_csv("data/processed/synth_features.csv")` and `df.to_sql("features", con, if_exists="replace", index=False)`  
  Loads the processed CSV into a pandas DataFrame and writes it to the SQLite database as a table named `features`. `if_exists="replace"` overwrites any existing table with the same name; `index=False` prevents pandas from adding the DataFrame index as a separate column.

- `df["weekday"] = df["weekday"].astype(int)`  
  Ensures the `weekday` column uses an integer type compatible with SQL joins and the `weekday_meta` table.

- Creating the `weekday_meta` DataFrame and writing it to SQL (`weekday_meta`)  
  This small lookup table provides a human-readable `weekday_name` for join demonstrations. Storing reference/metadata tables in the same database is a common pattern for self-contained examples.

- The SQL query string `q`  
  The query selects date, price, volume, log return, 5-day simple moving average (`sma_5`), and the weekday name by joining `features` (`f`) with `weekday_meta` (`m`) using the `weekday` column. `USING(weekday)` is a concise SQL shorthand that matches the column in both tables; it is equivalent to `ON f.weekday = m.weekday`. `ORDER BY date LIMIT 10` sorts results by date and returns only the first ten rows — useful for quick previews.

- `pd.read_sql(q, con)` and `print(...)`  
  Executes the SQL query against the SQLite connection and returns the result as a pandas DataFrame, which is then printed to stdout. Using `pandas.read_sql` is convenient for moving data between SQL and pandas for analysis or display.

- `finally: con.close()`  
  Ensures the SQLite connection is closed regardless of success or failure, releasing file handles and flushing changes.

```{bash}
set -euo pipefail
python3 scripts/make_sqlite.py
```

Shell-run explanations:

- `set -euo pipefail`  
  A shell safety idiom that makes scripts fail-fast: `-e` exits on any non-zero command status, `-u` treats unset variables as errors, and `-o pipefail` causes a pipeline to fail if any component fails. While not SQLite-specific, it helps ensure the Python script's failures are propagated to the shell.

- `python3 scripts/make_sqlite.py`  
  Runs the Python script that creates/populates `db/synth.db` and executes the example SQL query. After running, check `db/synth.db` with SQLite tools (for example `sqlite3 db/synth.db` or GUI clients) to inspect the `features` and `weekday_meta` tables and to run ad-hoc queries.