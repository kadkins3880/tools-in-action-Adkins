{
  "hash": "83ea95100b2b58dddfb921b60de66db0",
  "result": {
    "engine": "jupyter",
    "markdown": "# 08_pytest.qmd\n\n---\ntitle: \"08 — pytest (Simple Tests)\"\nformat: html\nexecute:\n  echo: true\n---\n\nIntroduction — This page contains simple pytest tests that validate processed CSV/Parquet artifacts and demonstrate how to run the test suite from the repository root. Explanations below describe what each test asserts and how the test run is invoked.\n\n::: {#883ba5d3 .cell execution_count=1}\n``` {.python .cell-code}\nimport os\nimport pandas as pd\n\ndef test_synth_features_columns_and_no_nans_price():\n    df = pd.read_csv(\"data/processed/synth_features.csv\")\n    expected = {\"date\",\"price\",\"volume\",\"log_return\",\"sma_5\",\"weekday\"}\n    assert expected.issubset(set(df.columns)), f\"Missing expected cols: {expected - set(df.columns)}\"\n    assert df[\"price\"].isna().sum() == 0\n\ndef test_date_monotonic_in_parquet():\n    df = pd.read_parquet(\"data/processed/synth.parquet\")\n    df[\"date\"] = pd.to_datetime(df[\"date\"])\n    assert df[\"date\"].is_monotonic_increasing, \"Date column is not monotonic increasing\"\n\ndef test_parquet_exists_and_size():\n    path = \"data/processed/synth.parquet\"\n    assert os.path.exists(path), \"Parquet file missing\"\n    assert os.path.getsize(path) > 0, \"Parquet file exists but is empty\"\n```\n:::\n\n\nExplanation for the above tests:\n\n- `test_synth_features_columns_and_no_nans_price()`  \n  - Loads `data/processed/synth_features.csv` into a DataFrame.  \n  - Verifies the presence of the expected columns: `date`, `price`, `volume`, `log_return`, `sma_5`, and `weekday`. If any are missing the assertion fails and the failure message shows which columns are absent.  \n  - Verifies there are no missing (`NaN`) values in the `price` column; the test fails if any `NaN`s are present. These checks ensure the processed CSV has the required schema and that the `price` column is complete.\n\n- `test_date_monotonic_in_parquet()`  \n  - Reads `data/processed/synth.parquet` into a DataFrame and ensures the `date` column is parsed as datetimes.  \n  - Asserts that `df[\"date\"].is_monotonic_increasing` is `True`, i.e., the date column is strictly non-decreasing down the rows. This guards against unordered or shuffled time-series data which can break time-based analyses.\n\n- `test_parquet_exists_and_size()`  \n  - Asserts that the Parquet file `data/processed/synth.parquet` exists on disk.  \n  - Asserts the file size is greater than zero (not empty). This is a basic sanity check that a previous processing step successfully wrote the Parquet artifact.\n\nNotes on test design:\n- Tests use straightforward, fast I/O checks and pandas semantics to assert correctness; keep tests small and deterministic to make them reliable in CI.\n- Assertion messages provide actionable feedback (e.g., which columns are missing) to speed debugging when tests fail.\n\n```{bash}\nset -euo pipefail\npytest -q\n```\n\nExplanation for the above commands:\n\n- `set -euo pipefail` is a shell safety idiom used when running the test command from a shell script or CI step:\n  - `-e` exits immediately if any command returns a non-zero status.\n  - `-u` treats unset variables as errors.\n  - `-o pipefail` causes a pipeline to return a non-zero exit if any component fails.\n  Using this ensures the test run fails loudly and stops subsequent shell commands when a problem occurs.\n\n- `pytest -q` runs the pytest test discovery and execution in quiet mode (`-q`), which produces concise output (dots or short summaries) suitable for CI logs or quick local runs. Run this from the repository root so file paths like `data/processed/synth_features.csv` and `data/processed/synth.parquet` resolve correctly.\n\n",
    "supporting": [
      "08_pytest_files"
    ],
    "filters": [],
    "includes": {}
  }
}